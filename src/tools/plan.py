from mirascope import llm
from src.utils.load_prompts import load_plan_prompt


@llm.tool
def plan(task: str, current_context: str = "", available_tools: str = "") -> str:
    """Create a detailed plan for completing a task.

    This tool acts as a sub-agent that analyzes a task and creates a step-by-step plan
    for completion. It considers the current context and available tools to generate
    a realistic, actionable plan.

    Args:
        task: The main task or goal to plan for (clear and specific)
        current_context: Current situation, constraints, or background information
        available_tools: List of tools or capabilities available for executing the plan

    Returns:
        A structured plan with numbered steps, estimated complexity, and any considerations.
    """
    try:
        # Load the planning prompt template
        prompt_template = load_plan_prompt()

        # Build the final prompt with context
        prompt = prompt_template.format(
            task=task,
            current_context=current_context,
            available_tools=available_tools if available_tools else "File operations (create, read, edit), bash execution, git operations, planning."
        )

        # Use the main model to generate the plan
        model = llm.Model(
            "vllm/vllm",
            max_tokens=8196,
            thinking={"level": "high", "include_thoughts": True}
        )

        messages = [
            llm.messages.system("You are an expert task planner. Provide clear, actionable plans."),
            llm.messages.user(prompt),
        ]

        response = model.stream(messages)

        # Collect the full response
        plan_text = ""
        for stream in response.streams():
            match stream.content_type:
                case "text":
                    for chunk in stream:
                        plan_text += chunk
                case "thought":
                    # Thoughts are internal, don't include in plan output
                    pass
                case "tool_call":
                    # Shouldn't happen for planning, but handle gracefully
                    pass

        return f"## Plan for: {task}\n\n{plan_text}\n\n---\n*Generated by plan tool*"

    except Exception as e:
        return f"Error generating plan: {str(e)}\n\nPlease try rephrasing the task or providing more context."
